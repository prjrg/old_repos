{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1,2],[3,4],[5,6],[7,8]]\n",
    "y = [[3],[7],[11],[15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(x).float()\n",
    "Y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(device)\n",
    "Y = Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        \n",
    "    def __getitem__(self, ix):\n",
    "        return self.x[ix], self.y[ix]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-c99224079c38>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x = torch.tensor(x).float()\n",
      "<ipython-input-7-c99224079c38>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y).float()\n"
     ]
    }
   ],
   "source": [
    "ds = MyDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_to_hidden_layer = nn.Linear(2,8)\n",
    "        self.hidden_layer_activation = nn.ReLU()\n",
    "        self.hidden_to_output_layer = nn.Linear(8,1)\n",
    "    def forward(self, x):\n",
    "        x = self.input_to_hidden_layer(x)\n",
    "        x = self.hidden_layer_activation(x)\n",
    "        x = self.hidden_to_output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = MyNeuralNet().to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "from torch.optim import SGD\n",
    "opt = SGD(mynet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47753357887268066\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "loss_history = []\n",
    "start = time.time()\n",
    "for _ in range(50):\n",
    "    for data in dl:\n",
    "        x, y = data\n",
    "        opt.zero_grad()\n",
    "        loss_value = loss_func(mynet(x), y)\n",
    "        loss_value.backward()\n",
    "        opt.step()\n",
    "        loss_history.append(loss_value)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = [[10, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = torch.tensor(val_x).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.3552]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_, y):\n",
    "    loss = (y_ - y)**2\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching intermediate layer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.1995, 1.0141, 0.0000, 0.0000, 1.9552, 1.2923, 0.0000],\n",
      "        [0.0000, 1.7831, 2.4878, 0.0000, 0.0000, 3.8180, 3.4059, 0.0000],\n",
      "        [0.0000, 2.3666, 3.9615, 0.0000, 0.0000, 5.6808, 5.5196, 0.0000],\n",
      "        [0.0000, 2.9502, 5.4352, 0.0000, 0.0000, 7.5436, 7.6332, 0.0000]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_to_hidden = mynet.input_to_hidden_layer(X)\n",
    "hidden_activation = mynet.hidden_layer_activation(input_to_hidden)\n",
    "print(hidden_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_to_hidden_layer = nn.Linear(2,8)\n",
    "        self.hidden_layer_activation = nn.ReLU()\n",
    "        self.hidden_to_output_layer = nn.Linear(8,1)\n",
    "    def forward(self, x):\n",
    "        hidden1 = self.input_to_hidden_layer(x)\n",
    "        hidden2 = self.hidden_layer_activation(hidden1)\n",
    "        output = self.hidden_to_output_layer(hidden2)\n",
    "        return output, hidden2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential methods to build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 8]                   24\n",
      "├─ReLU: 1-2                              [-1, 8]                   --\n",
      "├─Linear: 1-3                            [-1, 1]                   9\n",
      "==========================================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 8]                   24\n",
       "├─ReLU: 1-2                              [-1, 8]                   --\n",
       "├─Linear: 1-3                            [-1, 1]                   9\n",
       "==========================================================================================\n",
       "Total params: 33\n",
       "Trainable params: 33\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, torch.zeros(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1034541130065918\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "from torch.optim import SGD\n",
    "opt = SGD(model.parameters(), lr = 0.001)\n",
    "import time\n",
    "loss_history = []\n",
    "start = time.time()\n",
    "for _ in range(50):\n",
    "    for ix, iy in dl:\n",
    "        opt.zero_grad()\n",
    "        loss_value = loss_func(model(ix),iy)\n",
    "        loss_value.backward()\n",
    "        opt.step()\n",
    "        loss_history.append(loss_value)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = [[8,9],[10,11],[1.5,2.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.1109],\n",
       "        [21.1839],\n",
       "        [ 3.8762]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(val).float().to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.9452,  0.9224],\n",
       "                      [-0.3630,  0.3519],\n",
       "                      [-0.2643, -0.0199],\n",
       "                      [-0.0549, -0.5817],\n",
       "                      [ 0.2828, -0.3016],\n",
       "                      [ 0.1808,  0.0842],\n",
       "                      [ 0.2217, -0.1718],\n",
       "                      [ 0.4671,  0.0411]], device='cuda:0')),\n",
       "             ('0.bias',\n",
       "              tensor([-0.2878, -0.3410,  0.0140,  0.2367, -0.4587, -0.5723, -0.5047, -0.0751],\n",
       "                     device='cuda:0')),\n",
       "             ('2.weight',\n",
       "              tensor([[ 1.0109, -0.1794,  0.1976,  0.2850,  0.0663,  0.0969, -0.2824,  0.2433]],\n",
       "                     device='cuda:0')),\n",
       "             ('2.bias', tensor([0.2265], device='cuda:0'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), 'mymodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('mymodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.1109],\n",
       "        [21.1839],\n",
       "        [ 3.8762]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(val).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
