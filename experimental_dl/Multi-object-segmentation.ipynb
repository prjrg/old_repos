{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU openimages torch_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "!wget -O train-annotations-object-segmentation.csv -q https://storage.googleapis.com/openimages/v5/train-annotations-object-segmentation.csv\n",
    "!wget -O classes.csv -q https://raw.githubusercontent.com/openimages/dataset/master/dict.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_classes = 'person,dog,bird,car,elephant,football,jug,laptop,Mushroom,Pizza,Rocket,Shirt,Traffic sign,Watermelon,Zebra'\n",
    "required_classes = [c.lower() for c in required_classes.lower().split(',')]\n",
    "\n",
    "classes = pd.read_csv('classes.csv', header=None)\n",
    "classes.columns = ['class','class_name']\n",
    "classes = classes[classes['class_name'].map(lambda x: x in required_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "df = pd.read_csv('train-annotations-object-segmentation.csv')\n",
    "\n",
    "data = pd.merge(df, classes, left_on='LabelName', \n",
    "                right_on='class')\n",
    "\n",
    "subset_data = data.groupby('class_name').agg( \\\n",
    "                        {'ImageID': lambda x: list(x)[:500]})\n",
    "subset_data = flatten(subset_data.ImageID.tolist())\n",
    "subset_data = data[data['ImageID'].map(lambda x: x \\\n",
    "                                       in subset_data)]\n",
    "subset_masks = subset_data['MaskPath'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [08:41<06:45, 57.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c27385335786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtmp_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp_masks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'masks/{j}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c27385335786>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtmp_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp_masks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'masks/{j}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!mkdir -p masks\n",
    "for c in Tqdm('0123456789abcdef'):\n",
    "    !wget -q https://storage.googleapis.com/openimages/v5/train-masks/train-masks-{c}.zip\n",
    "    !unzip -q train-masks-{c}.zip -d tmp_masks\n",
    "    !rm train-masks-{c}.zip\n",
    "    tmp_masks = Glob('tmp_masks', silent=True)\n",
    "    items = [(m,fname(m)) for m in tmp_masks]\n",
    "    items = [(i,j) for (i,j) in items if j in subset_masks]\n",
    "    for i,j in items:\n",
    "        os.rename(i, f'masks/{j}')\n",
    "    !rm -rf tmp_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = Glob('masks')\n",
    "masks = [fname(mask) for mask in masks]\n",
    "\n",
    "subset_data = subset_data[subset_data['MaskPath'].map(lambda \\\n",
    "                                              x: x in masks)]\n",
    "subset_imageIds = subset_data['ImageID'].tolist()\n",
    "\n",
    "from openimages.download import _download_images_by_id\n",
    "!mkdir images\n",
    "_download_images_by_id(subset_imageIds, 'train', './images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "files = Glob('images') + Glob('masks') + \\\n",
    "['train-annotations-object-segmentation.csv', 'classes.csv']\n",
    "with zipfile.ZipFile('data.zip','w') as zipme:\n",
    "    for file in Tqdm(files):\n",
    "        zipme.write(file, compress_type=zipfile.ZIP_DEFLATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p train/\n",
    "!mv images train/myData2020\n",
    "!mv masks train/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \\\n",
    " git+git://github.com/waspinator/pycococreator.git@0.2.0\n",
    "import datetime\n",
    "\n",
    "INFO = {\n",
    "    \"description\": \"MyData2020\",\n",
    "    \"url\": \"None\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2020,\n",
    "    \"contributor\": \"sizhky\",\n",
    "    \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"MIT\"\n",
    "    }\n",
    "]\n",
    "\n",
    "CATEGORIES = [{'id': id+1, 'name': name.replace('/',''), \\\n",
    "               'supercategory': 'none'} \\\n",
    "              for id,(_,(name, clss_name)) in \\\n",
    "              enumerate(classes.iterrows())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocotools\n",
    "from pycococreatortools import pycococreatortools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "\n",
    "coco_output = {\n",
    "    \"info\": INFO,\n",
    "    \"licenses\": LICENSES,\n",
    "    \"categories\": CATEGORIES,\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"train\"\n",
    "IMAGE_DIR, ANNOTATION_DIR = 'train/myData2020/','train/annotations/'\n",
    "image_files = [f for f in listdir(IMAGE_DIR) if isfile(join(IMAGE_DIR, f))]\n",
    "annotation_files = [f for f in listdir(ANNOTATION_DIR) if \\\n",
    "                    isfile(join(ANNOTATION_DIR, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 1\n",
    "# go through each image\n",
    "for image_filename in Tqdm(image_files):\n",
    "    image = Image.open(IMAGE_DIR + '/' + image_filename)\n",
    "    image_info = pycococreatortools\\\n",
    "                    .create_image_info(image_id, \\\n",
    "                os.path.basename(image_filename), image.size)\n",
    "    coco_output[\"images\"].append(image_info)\n",
    "    image_id = image_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_id = 1\n",
    "for annotation_filename in Tqdm(annotation_files):\n",
    "    image_id = [f for f in coco_output['images'] if \\\n",
    "                stem(f['file_name']) == \\\n",
    "                annotation_filename.split('_')[0]][0]['id']\n",
    "    class_id = [x['id'] for x in CATEGORIES \\\n",
    "                if x['name'] in annotation_filename][0]\n",
    "    category_info = {'id': class_id, \\\n",
    "                    'is_crowd': 'crowd' in image_filename}\n",
    "    binary_mask = np.asarray(Image.open(f'{ANNOTATION_DIR}/{annotation_filename}').convert('1')).astype(np.uint8)\n",
    " \n",
    "    annotation_info = pycococreatortools\\\n",
    "                    .create_annotation_info( \\\n",
    "                    segmentation_id, image_id, category_info, \n",
    "                    binary_mask, image.size, tolerance=2)\n",
    "\n",
    "    if annotation_info is not None:\n",
    "        coco_output[\"annotations\"].append(annotation_info)\n",
    "        segmentation_id = segmentation_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output['categories'] = [{'id': id+1, 'name':clss_name, \\\n",
    "                              'supercategory': 'none'} for \\\n",
    "                             id,(_,(name, clss_name)) in \\\n",
    "                             enumerate(classes.iterrows())]\n",
    "\n",
    "import json\n",
    "with open('images.json', 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html\n",
    "!pip install pyyaml==5.1 pycocotools>=2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "required_classes= 'person,dog,bird,car,elephant,football,jug,\\\n",
    "laptop,Mushroom,Pizza,Rocket,Shirt,Traffic sign,\\\n",
    "Watermelon,Zebra'\n",
    "required_classes = [c.lower() for c in \\\n",
    "                    required_classes.lower().split(',')]\n",
    "\n",
    "classes = pd.read_csv('classes.csv', header=None)\n",
    "classes.columns = ['class','class_name']\n",
    "classes = classes[classes['class_name'].map(lambda \\\n",
    "                                x: x in required_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"dataset_train\", {}, \\\n",
    "                        \"images.json\", \"train/myData2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-\\ InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"dataset_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-\\ InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\") # pretrained \n",
    "# weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025 # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 5000 # instead of epochs, we train on \n",
    "# 5000 batches\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp output/model_final.pth output/trained_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \\\n",
    "                                 \"trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "files = Glob('train/myData2020')\n",
    "for _ in range(30):\n",
    "    im = cv2.imread(choose(files))\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], scale=0.5, \\\n",
    "                    metadata=MetadataCatalog.get(\\\n",
    "                              \"dataset_train\"), \\\n",
    "                    instance_mode=ColorMode.IMAGE_BW \n",
    "# remove the colors of unsegmented pixels. \n",
    "# This option is only available for segmentation models\n",
    "    )\n",
    "\n",
    "    out = v.draw_instance_predictions(\\\n",
    "                         outputs[\"instances\"].to(\"cpu\"))\n",
    "    show(out.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
